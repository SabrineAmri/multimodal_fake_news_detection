{"cells":[{"cell_type":"markdown","metadata":{"id":"CgJYqdVMrrWw"},"source":["**Step 1: Add Device Definition at the Beginning**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QyrXl9yqAl6Q"},"outputs":[],"source":["import torch\n","\n","# Define the device (GPU or CPU)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Check the device\n","print(f\"Using device: {device}\")\n"]},{"cell_type":"markdown","metadata":{"id":"y6PB-6zordGA"},"source":["**Step 2: Check GPU Availability**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fnihbJA_oKqV"},"outputs":[],"source":["import torch\n","print(torch.cuda.is_available())  # Should return True if GPU is available\n"]},{"cell_type":"markdown","metadata":{"id":"qnTEFhNTrXrN"},"source":["**Step 3: Install Required Libraries**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rr1RIOlhpRIF"},"outputs":[],"source":["!pip install transformers torch torchvision pandas scikit-learn"]},{"cell_type":"markdown","metadata":{"id":"nr_1cnrWrSzs"},"source":["**Step 4: Download the Dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pp6dAkbopZ7E"},"outputs":[],"source":["!git clone https://github.com/KaiDMML/FakeNewsNet.git\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JZP3Q7wYpjPc"},"outputs":[],"source":["!ls FakeNewsNet/dataset\n"]},{"cell_type":"markdown","metadata":{"id":"-QstBHQ9rNkc"},"source":["**Step 5: Load and Preprocess the Data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RPsq1q0Kp6H9"},"outputs":[],"source":["import pandas as pd\n","\n","# Load GossipCop data\n","df_fake_gossipcop = pd.read_csv('FakeNewsNet/dataset/gossipcop_fake.csv')\n","df_real_gossipcop = pd.read_csv('FakeNewsNet/dataset/gossipcop_real.csv')\n","\n","# Add label: 0 for fake, 1 for real\n","df_fake_gossipcop['label'] = 0\n","df_real_gossipcop['label'] = 1\n","\n","# Combine fake and real news data\n","df_combined = pd.concat([df_fake_gossipcop, df_real_gossipcop])\n","\n","# Check data\n","print(df_combined.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BSvpuNPQqOMW"},"outputs":[],"source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Tokenize a sample text from the dataset\n","def preprocess_text(text):\n","    inputs = tokenizer(text, return_tensors='pt', max_length=128, truncation=True, padding='max_length')\n","    return inputs['input_ids'], inputs['attention_mask']\n","\n","sample_text = df_combined['title'].iloc[0]\n","input_ids, attention_mask = preprocess_text(sample_text)\n"]},{"cell_type":"markdown","metadata":{"id":"csTTBsYhrCCL"},"source":["**Step 6: Model Definition: ViLBERT**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J85BlMPOqcJM"},"outputs":[],"source":["import torch.nn as nn\n","from transformers import BertModel\n","\n","class ViLBERTClassifier(nn.Module):\n","    def __init__(self):\n","        super(ViLBERTClassifier, self).__init__()\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","        self.classifier = nn.Linear(self.bert.config.hidden_size, 1)  # For binary classification\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        cls_output = outputs.last_hidden_state[:, 0, :]  # CLS token output\n","        logits = self.classifier(cls_output)\n","        return logits\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j1Iu_DrNqlwy"},"outputs":[],"source":["model = ViLBERTClassifier().cuda()  # Ensure the model is on the GPU\n"]},{"cell_type":"markdown","metadata":{"id":"K9QdaGaNq0Is"},"source":["**Step 7: Training Loop**"]},{"cell_type":"markdown","metadata":{"id":"r1pI7EmNsKlU"},"source":["7.1. Optimizer, loss function, and hyperparameters:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-cIc-ZiUqzDU"},"outputs":[],"source":["from torch.optim import Adam\n","\n","# Define the optimizer and loss function\n","optimizer = Adam(model.parameters(), lr=2e-5)\n","criterion = nn.BCEWithLogitsLoss()  # Binary classification loss\n"]},{"cell_type":"markdown","metadata":{"id":"x5YLPUFnsNFk"},"source":["7.2.Training loop:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZHUh_zdbsGjS"},"outputs":[],"source":["def train(model, train_loader, optimizer, criterion, device):\n","    model.train()\n","    total_loss = 0\n","\n","    for batch in train_loader:\n","        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n","\n","        optimizer.zero_grad()\n","        logits = model(input_ids, attention_mask)\n","        loss = criterion(logits.squeeze(), labels.float())\n","        total_loss += loss.item()\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    return total_loss / len(train_loader)\n"]},{"cell_type":"markdown","metadata":{"id":"3padiu8qsbi1"},"source":["**Step 8: DataLoader and Training Execution**"]},{"cell_type":"markdown","metadata":{"id":"l4z7z3AYshLi"},"source":["8.1. Create the DataLoader for training:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9c88uVx8sc8V"},"outputs":[],"source":["from torch.utils.data import DataLoader, TensorDataset\n","import torch\n","\n","# Prepare data for DataLoader\n","input_ids_list, attention_mask_list, labels_list = [], [], []\n","for text, label in zip(df_combined['title'], df_combined['label']):\n","    input_ids, attention_mask = preprocess_text(text)\n","    input_ids_list.append(input_ids)\n","    attention_mask_list.append(attention_mask)\n","    labels_list.append(torch.tensor(label))\n","\n","# Convert lists to tensors\n","dataset = TensorDataset(torch.cat(input_ids_list), torch.cat(attention_mask_list), torch.tensor(labels_list))\n","\n","# Create DataLoader\n","train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n"]},{"cell_type":"markdown","metadata":{"id":"7plAwAHWsmBD"},"source":["8.2. Train the model:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rq6dJDdVspiD"},"outputs":[],"source":["num_epochs = 3  # You can adjust based on your computational capacity\n","\n","for epoch in range(num_epochs):\n","    train_loss = train(model, train_loader, optimizer, criterion, device='cuda')\n","    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}')\n"]},{"cell_type":"markdown","metadata":{"id":"zhvwrZ_P9Ug7"},"source":["8.3 Create the Test DataLoader:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fsW9AxBJ9L8r"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Split the data into training and testing sets (e.g., 80% train, 20% test)\n","train_texts, test_texts, train_labels, test_labels = train_test_split(\n","    df_combined['title'], df_combined['label'], test_size=0.2, random_state=42)\n","\n","# Preprocess and prepare the data for the test loader\n","test_input_ids_list, test_attention_mask_list, test_labels_list = [], [], []\n","for text, label in zip(test_texts, test_labels):\n","    input_ids, attention_mask = preprocess_text(text)\n","    test_input_ids_list.append(input_ids)\n","    test_attention_mask_list.append(attention_mask)\n","    test_labels_list.append(torch.tensor(label))\n","\n","# Convert test lists to tensors\n","test_dataset = TensorDataset(\n","    torch.cat(test_input_ids_list),\n","    torch.cat(test_attention_mask_list),\n","    torch.tensor(test_labels_list)\n",")\n","\n","# Create the test DataLoader\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"]},{"cell_type":"markdown","metadata":{"id":"85tNkFzu09vm"},"source":["**Step 9: Saving the Model Correctly**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DsEJLWd5z4PP"},"outputs":[],"source":["# Correct way to save the model using PyTorch\n","model_save_path = 'vilbert_fakenews_model.pth'\n","\n","# Save only the model's state_dict (weights).\n","#torch.save(model.state_dict(), path), This saves the modelâ€™s learned parameters (weights).\n","torch.save(model.state_dict(), model_save_path)\n","\n","# To load the model back, use:\n","# model = VilBERTClassifier()\n","# model.load_state_dict(torch.load(model_save_path)) #This will be used later to load the saved weights into the same model architecture when needed.\n","# model.to(device)\n"]},{"cell_type":"markdown","metadata":{"id":"gmU2AgoI0_8w"},"source":["**Step 10: Downloading the Model to Your Local Machine**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xvT9kdlf1NLA"},"outputs":[],"source":["from google.colab import files\n","\n","# Download the saved model file\n","files.download('vilbert_fakenews_model.pth')\n"]},{"cell_type":"markdown","metadata":{"id":"0MM9wAW21ysa"},"source":["**Step 11: Evaluating the Model on Test Data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k8U3k23j10e8"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","def evaluate_model(model, test_loader, device):\n","    model.eval()  # Set model to evaluation mode\n","    predictions, true_labels = [], []\n","\n","    with torch.no_grad():  # Turn off gradients for evaluation\n","        for input_ids, attention_mask, labels in test_loader:\n","            input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n","            labels = labels.to(device)\n","\n","            # Forward pass, get predictions\n","            outputs = model(input_ids, attention_mask)\n","            logits = outputs.squeeze().cpu().numpy()  # Convert to numpy for easier handling\n","            preds = (logits > 0.5).astype(int)  # Apply threshold to get binary predictions\n","\n","            predictions.extend(preds)\n","            true_labels.extend(labels.cpu().numpy())\n","\n","    accuracy = accuracy_score(true_labels, predictions)\n","    precision = precision_score(true_labels, predictions)\n","    recall = recall_score(true_labels, predictions)\n","    f1 = f1_score(true_labels, predictions)\n","\n","    print(f'Accuracy: {accuracy:.4f}')\n","    print(f'Precision: {precision:.4f}')\n","    print(f'Recall: {recall:.4f}')\n","    print(f'F1-Score: {f1:.4f}')\n","\n","# Evaluate the model\n","evaluate_model(model, test_loader, device)\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPPaIFBNKMDyeXktwKvlb4W","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
